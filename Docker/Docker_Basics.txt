

    Learning Kubernetes and docker:
==============================================


 -> docker is a tool for running applications in an isolated environment
 -> similar to VM but it is much faster and does not require a lot of memory or an OS to run
 -> App run in same environmet
 -> Standard for software deployment

    Containers vs VM
_____________________________________________

 CONTAINERS:
 -> Containers are an abstraction at the app layer that packages *code* and *dependencies* together.
 -> Multiple containers can run on the same machine and *share the OS kernel* with other containers, 
    each running as isolated processes in user space.
 
 Infrastructure --> Host OS --> Docker --> App A
                                       --> App B
                                       --> App C

 VIRTUAL MACHINES:
 -> Virtual machines(VM) are an abstraction of physical hardware turning one server into many servers.
 -> The hypervisor allows multiple VMs to run on a single machine.
 -> Each VM includes a full copy of an operating system, the application, necessary binaries and 
    libraries- taking up tens of GBs. 
 -> VMs can also be slow to boot.

 Infrastructure --> Hypervisor --> VM1 --> Guest OS1 --> appA
                               --> VM2 --> Guest OS2 --> appB
                               --> VM3 --> Guest OS3 --> appC

 Benefits :
 -> Run container in seconds instead of minutes
 -> Less resources results less disk space
 -> Uses less memory
 -> does not need full OS
 -> Deployment
 -> Testing

 Installing Docker:
 ==> docs.docker.com/install
    Install Docker Desktop

Always run docker daemon(app) before running commands

=====+++++
 Docker Image:
 -> Image is a template for creating an environment of your choice
 -> Snapshot
 -> Has everything need to run your Apps
 -> OS, Software, App Code

 Container:
 -> Running instance of image

    image --> Run --> Container

 $ docker ps --> list all running containers where ps is process status

 $ docker pull nginx --> pulling image from docker hub 
   Status: Downloaded newer image for nginx:latest    --> here is the msg that is getting displayed where ":latest" is the tag

 $ docker images --> list all images
   REPOSITORY   TAG       IMAGE ID       CREATED        SIZE 

## Running a container from an image:
 $ docker run nginx:latest --> it will run the instance of this image
 $ docker run -d nginx:latest --> -d means run in dettach mode

 $ docker container ls --> list all container

 $ docker stop <container_id>  --> to stop the container

 EXPOSING Ports :
---------------------------
now for above case the nginx is exposing a port and the port is 80
mapping localhost 8080 to 80 of nginx

 -p 8080:80

 $ docker run -d -p 8080:80 nginx:latest

ealrlier ports --> 80/tcp
now after adding -p ports become --> 0.0.0.0:8080->80/tcp

if you go to localhost:8080 in your browser you will nginx welcome page

 Exposing multiple ports:
---------------------------
 docker run -d -p 8080:80 -p 3000:80 nginx:latest

 MANAGING Containers:
---------------------------
 $ docker stop <container_id>/<container_name> --> to stop the container (it does not remove the container)
 $ docker start <container_id>/<container_name> --> restart the container

 $ docker ps --> running containers
 $ docker ps --help
 $ docker ps -a --> list all running as well as stoped containers
 $ docker rm <container_id>/<container_name> --> to delete the container
 $ docker ps -a -q --> here -q shows only container id
 $ docker rm $(docker ps -aq) --> deleting all containers(only if all containers are stopped) use -f to force to remove the container


 NAMING CONTAINER:
----------------------------
 --name
 $ docker run --name website -d -p 3000:80 -p 8080:80 nginx:latest --> it will give name as website to container
 
 $ docker run --name website-two -d -p 9000:80 nginx:latest

 $ export FORMAT="ID\t{{.ID}}\n"  ---> your format
 $ docker ps --format=$FORMAT
 

 Docker Volumes
---------------------------
 -> Allows sharing of data.files and folders
 -> Between host and container
 -> Between containers.

 $ docker run --name website -v $(pwd):/usr/share/nginx/html:ro -p 8080:80 -d nginx  --> mount your host file path to container path which 
                    we got from documentation :ro means read only
    Now whatever is in your folder will be reflected in docker container and works same as debug mode your changes will be reflected live

 $ docker exec -it website bash  --> execute docker comaand in interactive mode(-it) on the container name specified  and we want to execute the bash command
 $ docker exec -it <container_name> <method> 
        If you try to create new file on that location it won't allow as it is read only
 to close --> use ctrl+D or $ exit
 
 $ docker run --name website -v $(pwd):/usr/share/nginx/html -p 8080:80 -d nginx --> now it will be for both read and write
 $ docker exec -it website bash
   $$ cd /usr/share/nginx/html
   $$ ls -al
   $$ touch about.html  --> this will be created in your host machine also

Search bootstrap landing page theme and use any template and copy from github code

   SHARING between CONTAINERS::
 $ docker run --help
 $ docker run --name website-copy --volumes-from website -d -p 8081:80 nginx  --> here --volumes-from will copy files/folders from website container

 Dockerfile :
---------------------------
 -> Build own images
 -> It consist of steps on how to create images
 -> When containing your own image you don't need to mount the volume instead you have to copy everything into your image
 -> should contain everything all the dependencies, all the source code

 Create a "Dockerfile" in your root folder
 -> always start from "FROM" --> always create some image not from scratch
        --> FROM nginx:latest
        --> ADD . /usr/share/nginx/html --> it will copy your code from your current directory to the static folder location in docker container
 
 -> $ docker build --tag website:latest .  --> -t ot --tag and tag_name and location of your dockerfile
 -> $ docker image ls

 ############################################################

Install Node
create new folder --> UserService
 $ cd UserService 
 $ node --version
 $ npm init
   :yes
 $ ll
 $ npm install --save express
 
 Copy from installation guide of express js
 create index.js and paste it there

 $ node index.js --> to run

 ---------------------
 FROM node:latest
 WORKDIR /app  --> create new dir /app if does not exist inside container
 ADD . . --> copy every thing from our curr dir to app dir
 RUN npm install --> install all dependencies from our package.json
 CMD node index.js  

 $ docker build -t user-service:latest .   ---> tag should always be in lower case
 $ docker run --name user-api -d -p 3000:3000 user-service:latest
----------------------


 .dockerignore :
-----------------------------------

when we do $ npm install or $ npm i 
 one dir called node_modules is being created this we don't need to move to our docker container

create .dockerignore

 node_modules
 Dockerfile
 .git


 CACHING and LAYERS :
-----------------------------------

 $ npm i -S react webpack gulp grunt   --> i=install, -S = --save

 If the contents of the file which are not changing again and again you can use cache memory and it will not add it again and again and just copy the new changes
 so it will help in reducing the build time

 FROM node:latest
 WORKDIR /app
 ADD package*.json ./   ---> here you are copying the essential lib because these do not get changed again and again it will help to build fast with docker caching
                            so it will not copy it again it will just load from its cache memory
                            we are using ./   because when adding multiple files it shold be stored in folder so ./ means in docker dir 
 RUN npm install
 ADD . .
 CMD node index.js
______________________________________________________________________________________

ADD & COPY --> add and copy are almost same just add has some more features, it can directly copy from url and can unzip tar files
RUN & CMD --> whatever you run it will remain in build state and if give cmd it will be the last command before build completes
            if multiple CMD then it will ignore all CMD except the last and CMD works when docker runs the image
______________________________________________________________________________________

 PULLING ALPINE IMAGES:
-----------------------------------

As all images which we are creating is of very huge size and we want to minimize size of our images, we are going to use Alpine linux distro
Alpine is small size, secure

 $ docker pull node:lts-alpine
 $ docker image ls   or docker images

 $ docker pull nginx:alpine

 change in Dockerfile 
 node:latest --> node:alpine

 $ docker image rm <image-id> --> to remove image



 TAGS, VERSIONING and TAGGING:
-----------------------------------
 -> Allows you to control image version
 -> Avoids breaking changes
 -> Safe

 If your frameworks version change and you keep it as latest then it will fail, so always mention version along with tag
 FROM nginx:1.17.2-alpine
 ADD . /usr/share/nginx/html

 FROM node:10.16.1-alpine  --> here version is of node 10.16.1 and alpine distribution

 RUNNING CONTAINERS and TAGS:
-----------------------------------
 $ docker build -t website:latest .
 $ docker run --name website -d -p 8080:80 website:layest 

 $ docker build -t user-service-api .
 $ docker run --name user-api -d -p 3000:80 user-service

 TAGGING OVERRIDE :
-----------------------------------
 $ docker images   --> some have no repository some has no tag ---- <none>   <none> this is because of overriding

 $ docker build -t evilscode-website:latest .
 $ docker tag evilscode-website:latest evilscode-website:1

 $ docker images
 change something in your code and again create a new image and again tag with new version
 
 $ docker build -t evilscode-website:latest .
 $ docker tag evilscode-website:latest evilscode-website:2
 
 Now you have 3 images 
 1. latest
 2. copy of latest i.e 2 with the new changes
 3 old version of code with tag as 1

 DOCKER REGISTRIES :
------------------------------------
 -> Highly Scalable server side application that stores and lets you distribute Docker images.
 -> Used in your CD/CI Pipeline  (Continuous delivery/ Continuous integration)
 -> Run your application

 Two typesof registry:
 1. Private   2.Public
 
 DockerHub
 quay.io
 Amazon ECR

 Go to dockerhub -> Repositories (you get only 1 private repo) -> create new public repo (similar to github)

 PUSHING IMAGES TO DOCKERHUB:
------------------------------------
 reponame : webiste
 docker push <username>/<reponame>:<tagname>
  
 $ docker tag website:latest evilriser/website:latest
 $ docker tag evilscode-website:1 evilriser/website:1

 $ docker login
  username:
  pwd: 
 
 $ docker push evilriser/website:latest
 $ docker push eviliser/website:1

 PULLING IMAGES:
----------------------------------
 $ docker rmi <image_name>:tag  --> deletes images

 $ docker rmi evilriser/website:latest
 $ docker rmi evilriser/webiste:1
 
 $ docker pull evilriser/webiste:latest

 DOCKER INSPECT:
----------------------------------
 $ docker inspect <container_id>

 DOCKER LOGS:
---------------------------------
 $ docker logs <container_id>
 $ docker logs -f <container_id>  --> -f means follow keeps on adding logs

 DOCKER EXEC:
--------------------------------
 $ dcoker exec -it <container_name> /bin/bash


 
